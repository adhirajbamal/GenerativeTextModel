# GenerativeTextModel
text generation system using both GPT-2 (transformers) and LSTM approaches
# Generative Text Model

Implementation of text generation models using both GPT-2 (transformers) and LSTM approaches.

## Features

- Two approaches to text generation:
  - GPT-2 (pretrained transformer model)
  - LSTM (custom trained character-level model)
- Interactive Jupyter notebook demo
- Pre-trained model support (GPT-2)
- Training code for custom LSTM models

## Installation

1. Clone this repository:
   ```bash
   git clone https://github.com/yourusername/generative-text-model.git
   cd generative-text-model

2. Install dependencies:
   pip install -r requirements.txt

Usage
Jupyter Notebook
Run the notebook for an interactive demo:

jupyter notebook text_generation.ipynb
